{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<table>\n",
    "  <tr>\n",
    "    <td><img src=\"https://portal.nccs.nasa.gov/datashare/astg/training/python/logos/nasa-logo.svg\" width=\"100\"/> </td>\n",
    "     <td><img src=\"https://portal.nccs.nasa.gov/datashare/astg/training/python/logos/ASTG_logo.png?raw=true\" width=\"80\"/> </td>\n",
    "     <td> <img src=\"https://www.nccs.nasa.gov/sites/default/files/NCCS_Logo_0.png\" width=\"130\"/> </td>\n",
    "    </tr>\n",
    "</table>\n",
    "</center>\n",
    "\n",
    "        \n",
    "<center>\n",
    "<h1><font color= \"blue\" size=\"+3\">ASTG Python Courses</font></h1>\n",
    "</center>\n",
    "\n",
    "---\n",
    "\n",
    "<center><h1><font color=\"red\" size=\"+3\">Introduction to Xarray</font></h1></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"red\">Useful References</font>\n",
    "- <a href=\"http://xarray.pydata.org/en/stable/\"> xarray</a>\n",
    "- <a href=\"http://gallery.pangeo.io/repos/pangeo-data/pangeo-tutorial-gallery/xarray.html\"> XARRAY TUTORIAL</a>\n",
    "- <a href=\"https://openresearchsoftware.metajnl.com/articles/10.5334/jors.148/\"> xarray: N-D labeled arrays and datasets in Python</a>\n",
    "- <a href=\"https://nbviewer.jupyter.org/github/mccrayc/tutorials/blob/master/2_reanalysis/CFSR_Data_Tutorial.ipynb\">Importing and mapping reanalysis data with xarray and cartopy</a>\n",
    "- <a href=\"https://openresearchsoftware.metajnl.com/articles/10.5334/jors.148/\">xarray: N-D labeled Arrays and Datasets in Python</a>\n",
    "- <a href=\"https://www.earthdatascience.org/courses/use-data-open-source-python/hierarchical-data-formats-hdf/use-netcdf-in-python-xarray/\">How to Open and Process NetCDF 4 Data Format in Open Source Python</a>\n",
    "- <a href=\"https://cbrownley.wordpress.com/tag/xarray/\">Visualizing Global Land Temperatures in Python with scrapy, xarray, and cartopy</a>\n",
    "- [Compare weighted and unweighted mean temperature](http://xarray.pydata.org/en/stable/examples/area_weighted_temperature.html)\n",
    "- [Example Weighted/masked average](https://nordicesmhub.github.io/NEGI-Abisko-2019/training/Example_model_global_arctic_average.html)\n",
    "- [Xarray Development Roadmap](http://xarray.pydata.org/en/stable/roadmap.html)\n",
    "- [Xarray Introduction and Tutorial](https://boisestate.hosted.panopto.com/Panopto/Pages/Embed.aspx?id=a38a2efc-1ac6-4c02-af0f-acfc015e9444)\n",
    "- [Xarray: Empowering Scientific Data Analysis within the NASA community](https://blogs.nasa.gov/transformtoopenscience/2023/08/07/xarray-empowering-scientific-data-analysis-within-the-nasa-community/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![fig_logo](https://docs.xarray.dev/en/stable/_static/Xarray_Logo_RGB_Final.svg)\n",
    "Image Source: docs.xarray.dev\n",
    "\n",
    "## <font color=\"red\">What is Xarray?</font>\n",
    "+ `Xarray` is an open source project and Python package that makes working with **labeled multi-dimensional arrays** simple and efficient.\n",
    "+ Introduces labels in the form of dimensions, coordinates and attributes on top of raw `NumPy`-like arrays, which allows for a more intuitive, more concise, and less error-prone developer experience. \n",
    "+ Is inspired by and borrows heavily from `Pandas`.\n",
    "+ Builds on top of, and seamlessly interoperates with, the core scientific Python packages, such as NumPy, SciPy, Matplotlib, and Pandas\n",
    "+ Is particularly tailored to working with `netCDF` files and integrates tightly with `Dask` for parallel computing.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"red\">Xarray and Real-World Data</font>\n",
    "\n",
    "- Real-world datasets, such as those generated by NASA, are often a collection of many related variables on a common grid.\n",
    "- These datasets are more than just arrays of values. They also have:\n",
    "   - Labels which describe how array values map to locations in dimensions such as space and time, and\n",
    "   - Metadata that describes how the data was collected and processed.\n",
    "- Xarray embraces the complexity of real-world datasets and enables users to use metadata such as dimension names and coordinate labels to easily analyze, manipulate, and visualize their datasets.\n",
    "- Xarray makes data analysis more intuitive and enjoyable, while describing how data was collected and processed. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"red\">Implementation and Architecture</font>\n",
    "- NetCDF forms the basis of the Xarray data model and provides a natural and portable serialization format. \n",
    "- Xarray features two main data structures (like `Pandas`): \n",
    "     - **DataArray** Xarray’s implementation of a labeled, multi-dimensional array. It has several key properties:\n",
    "          - *data*: N-dimensional array (NumPy or Dask) holding the array's values,\n",
    "          - *coords*: dict-like container of arrays (coordinates) that label each point (e.g., 1-dimensional arrays of numbers, datetime objects or strings),\n",
    "          - *dims*: dimension names for each axis [e.g., (‘time’, ‘latitude’, ‘longitude’)],\n",
    "          - *attrs*: OrderedDict holding arbitrary metadata (e.g. units or descriptions), and\n",
    "          - *name*: an arbitrary name for the array.\n",
    "     - **Dataset**: Xarray’s multi-dimensional equivalent of a DataFrame. It is a dict-like container of labeled arrays (DataArrays) with __aligned dimensions__. It is designed as an in-memory representation of a netCDF dataset. In addition to the dict-like interface of the dataset itself, which can be used to access any DataArray in a Dataset, datasets have four key properties:\n",
    "          - *data_vars*: OrderedDict of DataArray objects corresponding to data variables,\n",
    "          - *coords*: OrderedDict of DataArray objects intended to label points used in data_vars (e.g., 1-dimensional arrays of numbers, datetime objects or strings),\n",
    "          - *dims*: dictionary mapping from dimension names to the fixed length of each dimension (e.g., {‘x’: 6, ‘y’: 6, ‘time’: 8}), and\n",
    "          - *attrs*: OrderedDict to hold arbitrary metadata pertaining to the dataset.\n",
    "\n",
    "![fig_structure](https://tutorial.xarray.dev/_images/xarray-data-structures.png)\n",
    "Image Source: tutorial.xarray.dev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"red\">Core Xarray Features</font>\n",
    "\n",
    "- <u>*Serialization and I/O*</u>: xarray supports direct serialization and I/O to several file formats including pickle, netCDF, OPeNDAP (read-only), GRIB1/2 (read-only), and HDF by integrating with third-party libraries.\n",
    "- <u>*Metadata*</u>: Keep track of arbitrary metadata in the form of a Python dictionary. `x.attrs`.\n",
    "- <u>*Label-based indexing*</u>: Similarly to Pandas objects, xarray objects support both integer- and label-based lookups along each dimension. However, xarray objects also have named dimensions, so you can optionally use dimension names instead of relying on the positional ordering of dimensions. `x.loc['2014-01-01']` or `x.sel(time='2014-01-01')`\n",
    "- <u>*Arithmetic*</u>: arithmetic between xarray objects vectorizes based on dimension names, automatically looping (broadcasting) over each distinct dimension. This eliminates the need to insert dummy dimensions of size one to facilitate broadcasting, a common pattern with NumPy.\n",
    "- <u>*Aggregation*</u>: calculation of statistics (e.g. sum) along a dimension of an xarray object can be done by dimension name instead of an integer axis number. `x.sum('time')`\n",
    "- <u>*Plotting*</u>: Plotting functionality is a thin wrapper around Matplotlib. The syntax and function names from Matplotlib are used whenever possible, resulting in a seamless transition between the two.\n",
    "- <u>*Missing Data*</u>: Are smoothly handled in all operations, including arithmetic, alignment and aggregation.\n",
    "- <u>*Interactivity with Pandas*</u>: xarray objects seamlessly to convert to and from pandas objects to interact with the rest of the PyData ecosystem.\n",
    "- <u>*Out-of-core computation*</u>: xarray’s data structures can be backed by dask to support parallel and streaming computation on data that does not fit into memory, up to 100s of GB or TBs in size. \n",
    "- <u>*Alignment*</u>: Support of  database-like join operations for combining xarray objects along common coordinates.\n",
    "- <u>*Split-apply-combine*</u>: xarray includes N-dimensional grouped operations implementing the split-apply-combine strategy. `x.groupby('time.dayofyear').mean()`\n",
    "- <u>*Resampling and rolling window operations*</u>: Utilizing the efficient resampling methods from Pandas and rolling window operations from Bottleneck, xarray offers a robust set of resampling and rolling window operations along a single dimension."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"red\">Supported File Types</font>\n",
    "\n",
    "`Xarray`  supports direct serialization and IO to several [file formats](https://docs.xarray.dev/en/stable/user-guide/io.html) including:\n",
    "\n",
    "- Pickle\n",
    "- netCDF 3/4 format (recommended)\n",
    "- RaterIO\n",
    "- Zarr: a Python package providing an implementation of chunked, compressed, N-dimensional arrays. Zarr has the ability to store arrays in a range of ways, including in memory, in files, and in cloud-based object storage such as Amazon S3 and Google Cloud Storage. \n",
    "- GRIB format: thereading of GRIB files is done using the ECMWF `cgrib` Python driver (`engine='cfgrib'` as argument of `open_dataset`).\n",
    "- Xarray can read GRIB, HDF4 and other file formats supported by PyNIO (`engine='pynio'` as argument of `open_dataset`).\n",
    "- Xarray can also read HDF5 files using the `h5netcdf` engine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### <font color='red'> Only run the following cell if you are on Google Colab</font>\n",
    "\n",
    "Uncomment the cell below if you are on Google Colab. Unfortunately this might no longer work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!apt-get install libproj-dev proj-data proj-bin\n",
    "#!apt-get install libgeos-dev\n",
    "#!pip install cython\n",
    "#!pip install cartopy\n",
    "#!python -m pip install dask[dataframe] --upgrade\n",
    "#!pip install netCDF4\n",
    "#!pip install xarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy\n",
    "from cartopy.mpl.ticker import LongitudeFormatter, LatitudeFormatter\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "import cartopy.io.shapereader as shapereader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import netCDF4\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import dask\n",
    "import dask.array as da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version of Numpy:   1.26.4\n",
      "Version of Pandas:  2.2.1\n",
      "Version of netCDF4: 1.6.2\n",
      "Version of Xarray:  2023.6.0\n",
      "Version of Dask:    2023.11.0\n"
     ]
    }
   ],
   "source": [
    "print(f\"Version of Numpy:   {np.__version__}\")\n",
    "print(f\"Version of Pandas:  {pd.__version__}\")\n",
    "print(f\"Version of netCDF4: {netCDF4.__version__}\")\n",
    "print(f\"Version of Xarray:  {xr.__version__}\")\n",
    "print(f\"Version of Dask:    {dask.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Determine the system information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def convert_size(size):\n",
    "    \"\"\"\n",
    "    Convert from KB to another unit.\n",
    "    \"\"\"\n",
    "    if not size:\n",
    "        return '0B'\n",
    "    size_name = (\"B\", \"KB\", \"MB\", \"GB\", \"TB\", \"PB\", \"EB\", \"ZB\", \"YB\")\n",
    "    i = int(math.floor(math.log(size,1024)))\n",
    "    p = math.pow(1024,i)\n",
    "    s = round(size/p,2)\n",
    "    return \" \".join([str(s),size_name[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import platform\n",
    "import psutil\n",
    "\n",
    "print(f'{\"=\"*20} System Information {\"=\"*20}')\n",
    "uname = platform.uname()\n",
    "print(f\"           System: {uname.system}\")\n",
    "print(f\"        Node Name: {uname.node}\")\n",
    "print(f\"          Release: {uname.release}\")\n",
    "print(f\"          Version: {uname.version}\")\n",
    "print(f\"          Machine: {uname.machine}\")\n",
    "print(f\"        Processor: {uname.processor}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{\"=\"*20} CPU Information {\"=\"*20}')\n",
    "cpufreq = psutil.cpu_freq()\n",
    "print(f\"# logical cores = # physical cores times # threads \")\n",
    "print(f\"                    that can run on each physical core.\")\n",
    "print(f\"   Physical cores: {psutil.cpu_count(logical=False)}\")\n",
    "print(f\"    Logical cores: {psutil.cpu_count(logical=True)}\")\n",
    "print(f\"Current frequency: {psutil.cpu_freq().current}\")\n",
    "print(f\"    Min frequency: {psutil.cpu_freq().min}\")\n",
    "print(f\"    Max frequency: {psutil.cpu_freq().max}\")\n",
    "print()\n",
    "print(\"CPU Usage Per Core:\")\n",
    "for i, percentage in enumerate(psutil.cpu_percent(percpu=True, interval=1)):\n",
    "    print(f\"\\t Core {i}: {percentage}%\")\n",
    "print(f\"  Total CPU Usage: {psutil.cpu_percent()}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{\"=\"*20} Memory Information {\"=\"*20}')\n",
    "svmem = psutil.virtual_memory()\n",
    "print(f\"            Total: {convert_size(svmem.total)}\")\n",
    "print(f\"        Available: {convert_size(svmem.available)}\")\n",
    "print(f\"             Used: {convert_size(svmem.used)}\")\n",
    "print(f\"       Percentage: {svmem.percent}%\")\n",
    "print(f'{\"=\"*20} Swap Memory Details (if exists) {\"=\"*20}')\n",
    "swap = psutil.swap_memory()\n",
    "print(f\"            Total: {convert_size(swap.total)}\")\n",
    "print(f\"             Free: {convert_size(swap.free)}\")\n",
    "print(f\"             Used: {convert_size(swap.used)}\")\n",
    "print(f'{\"=\"*60}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disk Information\n",
    "print(f'{\"=\"*20} Disk Information {\"=\"*20}')\n",
    "print(\"Partitions and Usage:\")\n",
    "# get all disk partitions\n",
    "partitions = psutil.disk_partitions()\n",
    "for partition in partitions:\n",
    "    print(f\"=== Device: {partition.device} ===\")\n",
    "    print(f\"  Mountpoint: {partition.mountpoint}\")\n",
    "    print(f\"  File system type: {partition.fstype}\")\n",
    "    try:\n",
    "        partition_usage = psutil.disk_usage(partition.mountpoint)\n",
    "    except PermissionError:\n",
    "        # this can be catched due to the disk that\n",
    "        # isn't ready\n",
    "        continue\n",
    "    print(f\"  Total Size: {convert_size(partition_usage.total)}\")\n",
    "    print(f\"  Used: {convert_size(partition_usage.used)}\")\n",
    "    print(f\"  Free: {convert_size(partition_usage.free)}\")\n",
    "    print(f\"  Percentage: {partition_usage.percent}%\")\n",
    "# get IO statistics since boot\n",
    "disk_io = psutil.disk_io_counters()\n",
    "print(f\"Total read: {convert_size(disk_io.read_bytes)}\")\n",
    "print(f\"Total write: {convert_size(disk_io.write_bytes)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='red'>Basic Manipulations</font> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='blue'>Xarray DataArray</font>\n",
    "\n",
    "- Xarray’s implementation of a labeled, multi-dimensional array.\n",
    "- Has several key properties:\n",
    "    - `values`: a numpy.ndarray holding the array’s values\n",
    "    - `dims`: dimension names for each axis (e.g., `('time', 'lat', 'lon')`)\n",
    "    - `coords`: a dict-like container of arrays (coordinates) that label each point (e.g., 1-dimensional arrays of numbers, datetime objects or strings)\n",
    "    - `attrs`: dict to hold arbitrary metadata (attributes)\n",
    "    \n",
    "- Xarray uses `dims` and `coords` to enable its core metadata aware operations. \n",
    "- Dimensions provide names that xarray uses instead of the `axis` argument found in many NumPy functions. \n",
    "- Coordinates enable fast label based indexing and alignment, building on the functionality of the `index` found on a Pandas `DataFrame` or `Series`.\n",
    "\n",
    "Assume that we have several time records of a two dimensional surface temperature field. It can be represented as:\n",
    "\n",
    "$$T(x,y,t)$$\n",
    "\n",
    "where `x` and  `y` are spatial dimensions and and `t` is time. \n",
    "We want to create a Xarray object to"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Creating a DataArray**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us create a 3D Numpy array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ntimes = 7\n",
    "nlats = 5\n",
    "nlons = 6\n",
    "max_val, min_val = 1.0, -1.0\n",
    "range_size = max_val - min_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_data = 273.5 + 10 * (range_size*np.random.randn(ntimes, nlats, nlons) + min_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Data type:  \\n\\t {type(np_data)}\")\n",
    "print(f\"Data shape: \\n\\t {np_data.shape}\")\n",
    "print(f\"Numpy array: \\n {np_data}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a basic `DataArray` by passing it just a Numpy array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr_data = xr.DataArray(np_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Type: \\n\\t {type(xr_data)}\")\n",
    "print(f\"Xarray DataArray: \\n {xr_data}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `Xarray` generates some basic dimension names for us: `dim_0`, `dim_1`, `dim_2`.\n",
    "- We can also pass in our own dimension names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr_data = xr.DataArray(np_data, dims=['time', 'lat', 'lon'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We have named each of the dimensions.\n",
    "- We can take arrays representing the values for the coordinates for each of these dimensions and associate them with the data when we create the `DataArray`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can get the values of the data array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr_data.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(xr_data.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the dimension labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr_data.dims"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get values of the dimensions:\n",
    "\n",
    "- `Xarray` sets default values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr_data.time.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr_data.lat.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr_data.lon.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the coordinates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr_data.coords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let us include the coordinates.\n",
    "\n",
    "Use `Pandas` to create an array of datetimes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times = pd.date_range('2010-01-01', freq='12H', periods=ntimes)\n",
    "times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Latitude and longitude points:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lons = np.linspace(-120, -60, nlons)\n",
    "lats = np.linspace(30, 65, nlats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now pass the time, latitude and longitude values to include the coordinates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr_data = xr.DataArray(np_data, \n",
    "                       coords=[times, lats, lons], \n",
    "                       dims=['time', 'lat', 'lon'])\n",
    "xr_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can get again the coordinates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr_data.coords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get values of the dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr_data['time'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr_data.time.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr_data.lat.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr_data.lon.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attributes\n",
    "\n",
    "- We can add metadata attributes that can be use later for data manipulation and visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr_data.attrs['short_name'] = 'T'\n",
    "xr_data.attrs['long_name'] = 'surface_air_temperature'\n",
    "xr_data.attrs['units'] = 'K'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr_data.attrs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also add metadata to coordinate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr_data.lon.attrs[\"long_name\"] = \"longitude\"\n",
    "xr_data.lon.attrs[\"units\"] = \"degrees_east\"\n",
    "xr_data.lon.attrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr_data.lat.attrs[\"long_name\"] = \"latitude\"\n",
    "xr_data.lat.attrs[\"units\"] = \"degrees_north\"\n",
    "xr_data.lat.attrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr_data.time.attrs[\"long_name\"] = \"time\"\n",
    "xr_data.time.attrs[\"units\"] = \"Hours since 2010-01-01 00:00:00\"\n",
    "xr_data.time.attrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"green\">Exercise</font>\n",
    "\n",
    "We want to create a DataArray (`surf_data`) that has the surface pressure data:\n",
    "\n",
    "- The data values are in a Numpy array with $30 \\times 25$ grid points. \n",
    "    - All the values are initialized to `965.7`.\n",
    "    - The attribute units is `mb`.\n",
    "    - The attribute long_name is `surface pressure` and the one for short_name is `sp`.\n",
    "    - The valid_range attribute is `[550.0, 1525.0]`.\n",
    "    - The `missing_value` attribute is `-9999.0`.\n",
    "- The latitudes (25) and longitudes (30) cover the entire globe.\n",
    "    - The latitude and longitude attribute units are `degrees_north` and `degrees_east` respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "<p>\n",
    "\n",
    "<details><summary><b><font color=\"green\">Click here to access the solution</font></b></summary>\n",
    "<p>\n",
    "\n",
    "\n",
    "```python\n",
    "nlons = 30\n",
    "nlats = 25\n",
    "init_val = 967.5\n",
    "\n",
    "lats = np.linspace(-90, 90, nlats)\n",
    "lons = np.linspace(-180, 180, nlons) \n",
    "surf_pres = xr.DataArray(np.full((nlats, nlons), init_val), \n",
    "                       coords=[lats, lons], \n",
    "                       dims=['lat', 'lon'])\n",
    "\n",
    "surf_pres.attrs['short_name'] = 'sp'\n",
    "surf_pres.attrs['long_name'] = 'surface_pressure'\n",
    "surf_pres.attrs['units'] = 'mb'\n",
    "surf_pres.attrs['missing_value'] = -9999.0\n",
    "surf_pres.attrs['valid_range'] = [550.0, 1525.0]\n",
    "    \n",
    "surf_pres.lat.attrs[\"long_name\"] = \"latitude\"\n",
    "surf_pres.lat.attrs[\"units\"] = \"degrees_north\"\n",
    "\n",
    "surf_pres.lon.attrs[\"long_name\"] = \"longitude\"\n",
    "surf_pres.lon.attrs[\"units\"] = \"degrees_east\"\n",
    "\n",
    "```\n",
    "\n",
    "</p>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indexing\n",
    "\n",
    "- Xarray supports four kinds of indexing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Positional and by integer index, like NumPy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "xr_data[:,2,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`loc` or \"location\": positional and coordinate label, like Pandas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr_data.loc[:,47.5,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`isel` or \"integer select\":  by dimension name and integer label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr_data.isel(lat=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`sel` or \"select for label-based indexing\": \n",
    "\n",
    "- By dimension name and coordinate label.\n",
    "- Allow us to fetch values based on the value of the coordinate, not the numerical index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr_data.sel(lat=47.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Unlike positional indexing, label-based indexing frees us from having to know how our array is organized. \n",
    "- All we need to know are the dimension name and the label we wish to index i.e. `data.sel(lat=47.5)` works regardless of whether `lat` is the first or second dimension of the array and regardless of whether `47.5` is the first or second element of `lat`. \n",
    "- We have already told Xarray that `lat` is the second dimension when we created data: Xarray keeps track of this so we don’t have to."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Slicing with selection\n",
    "\n",
    "- Use the `slice` function alon a dimension to determine the range of coordinates we want to select."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr_data.sel(time=slice('2010-01-02', '2010-01-03'), \n",
    "            lon=slice(-100, -70), \n",
    "            lat=slice(35, 55))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use `loc` (array-like slicing) to obtain the same information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr_data.loc['2010-01-02':'2010-01-03', 35:55, -100:-70]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computations\n",
    "\n",
    "- When we perform mathematical manipulations of xarray DataArrays, the coordinates are also included.\n",
    "- DataArrays work similarly to Numpy arrays."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can scale and offset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr_data + 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use Numpy built-in functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.exp(-0.25*xr_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use `where()` to conditionally switch between values:\n",
    "\n",
    "```python\n",
    "  xr.where(cond, x, y)\n",
    "```\n",
    "\n",
    "- When `cond` is True, return values from `x`, otherwise returns values from `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr.where(xr_data > 287.5, np.nan, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr.where(xr_data > 287.5, np.nan, 1).isnull().count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can take the transpose:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr_data.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can sum all the entries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr_data.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the standard deviation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr_data.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr_data.std(dim=\"lat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr_data.std(dim=(\"lat\", \"lon\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aggregation operations can use dimension names instead of axis numbers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr_data.mean(dim=\"lat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr_data.mean(dim=\"lon\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can do similar calculations in `Numpy`. We need to specify the index of the axis of interest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_data.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_data.mean(axis=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Arithmetic operations broadcast are based on dimension name. \n",
    "- You don not need to insert dummy dimensions for alignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = xr.DataArray(np.random.random(nlats), [xr_data.coords[\"lat\"]])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = xr.DataArray(np.random.random(6), dims=\"lev\")\n",
    "b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![a+b](https://portal.nccs.nasa.gov/datashare/astg/training/python/xarray/broadcast.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a+b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b+a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may not need to worry about the order of dimensions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr_data - xr_data.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Operations also align based on index labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr_data[:-1] - xr_data[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpolation\n",
    "- `Xarray` does interpolation on the fly.\n",
    "- By default, the linear interpolation is used.\n",
    "- The available interpolation methods are:\n",
    "    - {`linear`, `nearest`} for multidimensional array.\n",
    "    - {`linear`, `nearest`, `zero`, `slinear`, `quadratic`, `cubic`} for 1-dimensional array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr_data.interp(lat=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr_data.interp(lat=40, method=\"nearest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr_data.interp(lat=40, lon=-100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr_data.interp(time=\"2010-01-02 18:00:00\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting\n",
    "\n",
    "Time series plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr_data.mean(dim=[\"lat\", \"lon\"]).plot(marker='o');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr_data.interp(time=\"2010-01-02 18:00:00\", lon=-102).plot.line();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr_data.mean(dim=('time', 'lon')).plot(marker='o');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vmin = xr_data.values.min()\n",
    "vmax = xr_data.values.max()\n",
    "xr_data.sel(time=\"2010-01-02 12:00:00\").plot(vmin=vmin, vmax=vmax);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr_data.sel(lon=-108.0).transpose().plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Going to Pandas\n",
    "\n",
    "Xarray objects can be easily converted to and from Pandas objects using the `to_series()`, `to_dataframe()` and `to_xarray()` methods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_series = xr_data.to_series()\n",
    "pd_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_series.to_xarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='blue'>Xarray Datasets</font>\n",
    "\n",
    "- `xarray.Dataset` is a dict-like container of aligned DataArray objects. \n",
    "- It can be seen as a multi-dimensional generalization of the `pandas.DataFrame`.\n",
    "- Variables in datasets can have different `dtype` and even different dimensions.\n",
    "- **All dimensions are assumed to refer to points in the same shared coordinate system**:\n",
    "     - If two variables have dimension `x`, that dimension must be identical in both variables.\n",
    "     \n",
    "Here is an example of how we might structure a dataset for a weather forecast:\n",
    "\n",
    "![fig_dataset](https://docs.xarray.dev/en/stable/_images/dataset-diagram.png)\n",
    "\n",
    "Image Source: docs.xarray.dev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can create a dataset with three `DataArrays` named `da_1`, `da_2` and `da_3`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr_dst = xr.Dataset({\"da_1\": xr_data, \n",
    "                     \"da_2\": (\"lat\", [7.5, 2.6, -6.4, 15.7, 3.7]), \n",
    "                     \"da_3\": np.pi})\n",
    "xr_dst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the dictionary or dot indexing to pull out `Dataset` variables as `DataArray` objects: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr_dst[\"da_1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr_dst.da_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Xarray automatically aligns `da_2` with `DataArray` `da_1`: they share the same coordinate system so that:\n",
    "\n",
    "`xr_dst.da_1['lat'] == xr_dst.da_2['lat'] == xr_dst['lat']`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr_dst.da_1.sel(lat=47.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr_dst.da_2.sel(lat=47.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving the Dataset to a netCDF file\n",
    "- We can save the dataset in a netCDF file by using the `to_netcdf` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nc_filename = \"sample_netcdf.nc\"\n",
    "xr_dst.to_netcdf(nc_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can read back the netCDF file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with xr.open_dataset(nc_filename) as fid:\n",
    "     print(fid.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='purple'>Using `Pandas DataFrames`</font> \n",
    "\n",
    "- We use web scrapping to access the <a href=\"https://neo.gsfc.nasa.gov/\">NASA Earth Observations (NEO)</a> website to obtain the AOT measurements for a given range of days (from 2000 to present).\n",
    "- For each daily reading, we create a `Pandas DataFrame` that is use to create a `Xarray DataArray`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests as reqs\n",
    "import io\n",
    "from bs4 import BeautifulSoup as bso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Select the day range of interest:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beg_date = '2019-01-01'\n",
    "end_date = '2019-12-31'\n",
    "data_freq = 'D' # daily ('D'), monthly 'M'\n",
    "\n",
    "datasetID = 'MODAL2_M_AER_OD'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dates(beg_date, end_date, freq='D'):\n",
    "    \"\"\"\n",
    "      Create a list containing all the dates between\n",
    "      beg_date and end_date.\n",
    "      \n",
    "      Input parameters:\n",
    "         - beg_date: (str) start date in the format YYYY-MM-DD\n",
    "         - end_date: (str) end   date in the format YYYY-MM-DD\n",
    "         - freq: (str) frequency - 'D' for days and 'M' for months\n",
    "      Returned value:\n",
    "         - a list of dates in the format YYYY-MM-DD\n",
    "    \"\"\"\n",
    "    pd_series = pd.date_range(start=beg_date, end=end_date, freq=freq)\n",
    "    list_dates = [dt.strftime('%Y-%m-%d') for dt in pd_series]\n",
    "    return list_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_urls(datasetID, list_dates, freq='D'):\n",
    "    \"\"\"\n",
    "      Create a list containing the urls for the websites we\n",
    "      want to access to grab the full addresses of the CVS files\n",
    "      (that have the mesurements).\n",
    "      \n",
    "      Input parameters:\n",
    "         - datasetID: (str) dataset identifier for the data of interest\n",
    "         - list_dates: (list) list of dates of interest\n",
    "      Returned value:\n",
    "         - a list of urls\n",
    "    \"\"\"\n",
    "    freq_tag = '&date='\n",
    "    if freq == 'M':\n",
    "        freq_tag = '&year='\n",
    "    elif freq == 'Y':\n",
    "        freq_tag = '&year='\n",
    "    url = 'https://neo.gsfc.nasa.gov/view.php?datasetId='\n",
    "    url_base = url+datasetID+'&date='\n",
    "    list_urls = [url_base+dt for dt in list_dates]\n",
    "    return list_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = generate_dates(beg_date, end_date, freq=data_freq)\n",
    "urls = generate_urls(datasetID, dates)\n",
    "\n",
    "assert len(urls) == len(dates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parse each website to obtain the location of the CSV files (containing measurements):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_urls = list()\n",
    "for url in urls:\n",
    "    source = reqs.get(url)\n",
    "    mysoup = bso(source.text, 'html.parser')\n",
    "    href_tags = mysoup.find_all(href=True)\n",
    "    for tag in href_tags:\n",
    "        loc_url = tag[\"href\"]\n",
    "        if \"CSV\" in loc_url:\n",
    "            csv_urls.append(loc_url)\n",
    "            break\n",
    "\n",
    "print(len(csv_urls), len(urls), len(dates))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read all the CSV files and create a Xarray DataSet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "das = list()\n",
    "dts = list()\n",
    "for i, csv_file in enumerate(csv_urls):\n",
    "    print(i, csv_file)\n",
    "    dts.append(pd.to_datetime(dates[i]))\n",
    "    \n",
    "    resp = reqs.get(csv_file)\n",
    "    df = pd.read_csv(io.StringIO(resp.text), \n",
    "                     index_col=0, na_values=99999.0)\n",
    "    da = xr.DataArray(df.values, \n",
    "                      coords=[[float(lat) for lat in df.index], \n",
    "                              [float(lon) for lon in df.columns]],\n",
    "                      dims=['latitude', 'longitude'])\n",
    "    \n",
    "    das.append(da)\n",
    "\n",
    "xr_dst = xr.concat(das, pd.Index(dts, name='date'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr_dst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotting\n",
    "\n",
    "First thirty days:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thirtydays = xr_dst[0:31]\n",
    "thirtydays.plot(x=\"longitude\", y=\"latitude\",\n",
    "                col=\"date\", col_wrap=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Average over the first thirty days:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thirtydays.mean(dim='date').plot(figsize=(10, 6), cmap='RdBu_r');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zoom over the USA:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "usa = thirtydays.sel(latitude=slice(50.05, 20.05),\n",
    "                 longitude=slice(-125.05, -66.50))\n",
    "usa.mean(dim='date').plot(cmap='RdBu_r');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "ax_p = plt.gca(projection=ccrs.LambertConformal(), aspect='auto')\n",
    "ax_p.coastlines()\n",
    "ax_p.set_extent([-125.05, -66.50, 20.05, 50.05])\n",
    "usa.mean(dim='date').plot.imshow(ax=ax_p, cmap='RdBu_r', \n",
    "                                 transform=ccrs.PlateCarree());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Monthly means:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_means = xr_dst.groupby(xr_dst.date.dt.month).mean(dim='date')\n",
    "monthly_means.plot(x='longitude', y='latitude', col='month', \n",
    "                   cmap='RdBu_r', col_wrap=4);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Annual Mean:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr_dst.mean(dim='date').plot(figsize=(10, 6), cmap='RdBu_r');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='green'> Exercise</font>\n",
    "\n",
    "The website \n",
    "\n",
    "[https://neo.gsfc.nasa.gov/](https://neo.gsfc.nasa.gov/)\n",
    "\n",
    "also contains measurements for:\n",
    "\n",
    "- Carbon Monoxide (`MOP_CO_M`)\n",
    "- Cloud optical Thickness (`MODAL2_M_CLD_OT`)\n",
    "- Cloud Fraction (`MODAL2_M_CLD_FR`)\n",
    "- Land Surface Temperature (`MOD_LSTD_CLIM_M`)\n",
    "- etc.\n",
    "\n",
    "Select one of them and retrieve dataset for a a given time period. You may want to first verify the raange of dates where the measurements are available."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='red'>Manipulating a netCDF File</font> \n",
    "\n",
    "- We will manipulate [NOAA NCEP Reanalysis](https://www.esrl.noaa.gov/psd/thredds/catalog/Datasets/ncep.reanalysis/surface/catalog.html) surface data.\n",
    "- The reanalysis project uses an analysis/forecast system to perform data assimilation using past data from 1948 to the present.\n",
    "- Spatial coverage: 2.5 degree latitude x 2.5 degree longitude global grid (144x73).\n",
    "- It produces outputs 4 times per day.\n",
    "- Here, we will focus on surface air temperature for 2018: 4x365 = 1460 records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%env HDF5_USE_FILE_LOCKING=FALSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#xr.set_options(file_cache_maxsize=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "url=\"https://psl.noaa.gov/thredds/dodsC/Datasets/ncep.reanalysis/surface/air.sig995.2018.nc\"\n",
    "ds = xr.open_dataset(url, engine='netcdf4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Content of the Dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><svg style=\"position: absolute; width: 0; height: 0; overflow: hidden\">\n",
       "<defs>\n",
       "<symbol id=\"icon-database\" viewBox=\"0 0 32 32\">\n",
       "<path d=\"M16 0c-8.837 0-16 2.239-16 5v4c0 2.761 7.163 5 16 5s16-2.239 16-5v-4c0-2.761-7.163-5-16-5z\"></path>\n",
       "<path d=\"M16 17c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n",
       "<path d=\"M16 26c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n",
       "</symbol>\n",
       "<symbol id=\"icon-file-text2\" viewBox=\"0 0 32 32\">\n",
       "<path d=\"M28.681 7.159c-0.694-0.947-1.662-2.053-2.724-3.116s-2.169-2.030-3.116-2.724c-1.612-1.182-2.393-1.319-2.841-1.319h-15.5c-1.378 0-2.5 1.121-2.5 2.5v27c0 1.378 1.122 2.5 2.5 2.5h23c1.378 0 2.5-1.122 2.5-2.5v-19.5c0-0.448-0.137-1.23-1.319-2.841zM24.543 5.457c0.959 0.959 1.712 1.825 2.268 2.543h-4.811v-4.811c0.718 0.556 1.584 1.309 2.543 2.268zM28 29.5c0 0.271-0.229 0.5-0.5 0.5h-23c-0.271 0-0.5-0.229-0.5-0.5v-27c0-0.271 0.229-0.5 0.5-0.5 0 0 15.499-0 15.5 0v7c0 0.552 0.448 1 1 1h7v19.5z\"></path>\n",
       "<path d=\"M23 26h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "<path d=\"M23 22h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "<path d=\"M23 18h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "</symbol>\n",
       "</defs>\n",
       "</svg>\n",
       "<style>/* CSS stylesheet for displaying xarray objects in jupyterlab.\n",
       " *\n",
       " */\n",
       "\n",
       ":root {\n",
       "  --xr-font-color0: var(--jp-content-font-color0, rgba(0, 0, 0, 1));\n",
       "  --xr-font-color2: var(--jp-content-font-color2, rgba(0, 0, 0, 0.54));\n",
       "  --xr-font-color3: var(--jp-content-font-color3, rgba(0, 0, 0, 0.38));\n",
       "  --xr-border-color: var(--jp-border-color2, #e0e0e0);\n",
       "  --xr-disabled-color: var(--jp-layout-color3, #bdbdbd);\n",
       "  --xr-background-color: var(--jp-layout-color0, white);\n",
       "  --xr-background-color-row-even: var(--jp-layout-color1, white);\n",
       "  --xr-background-color-row-odd: var(--jp-layout-color2, #eeeeee);\n",
       "}\n",
       "\n",
       "html[theme=dark],\n",
       "body[data-theme=dark],\n",
       "body.vscode-dark {\n",
       "  --xr-font-color0: rgba(255, 255, 255, 1);\n",
       "  --xr-font-color2: rgba(255, 255, 255, 0.54);\n",
       "  --xr-font-color3: rgba(255, 255, 255, 0.38);\n",
       "  --xr-border-color: #1F1F1F;\n",
       "  --xr-disabled-color: #515151;\n",
       "  --xr-background-color: #111111;\n",
       "  --xr-background-color-row-even: #111111;\n",
       "  --xr-background-color-row-odd: #313131;\n",
       "}\n",
       "\n",
       ".xr-wrap {\n",
       "  display: block !important;\n",
       "  min-width: 300px;\n",
       "  max-width: 700px;\n",
       "}\n",
       "\n",
       ".xr-text-repr-fallback {\n",
       "  /* fallback to plain text repr when CSS is not injected (untrusted notebook) */\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-header {\n",
       "  padding-top: 6px;\n",
       "  padding-bottom: 6px;\n",
       "  margin-bottom: 4px;\n",
       "  border-bottom: solid 1px var(--xr-border-color);\n",
       "}\n",
       "\n",
       ".xr-header > div,\n",
       ".xr-header > ul {\n",
       "  display: inline;\n",
       "  margin-top: 0;\n",
       "  margin-bottom: 0;\n",
       "}\n",
       "\n",
       ".xr-obj-type,\n",
       ".xr-array-name {\n",
       "  margin-left: 2px;\n",
       "  margin-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-obj-type {\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-sections {\n",
       "  padding-left: 0 !important;\n",
       "  display: grid;\n",
       "  grid-template-columns: 150px auto auto 1fr 20px 20px;\n",
       "}\n",
       "\n",
       ".xr-section-item {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-section-item input {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-section-item input + label {\n",
       "  color: var(--xr-disabled-color);\n",
       "}\n",
       "\n",
       ".xr-section-item input:enabled + label {\n",
       "  cursor: pointer;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-section-item input:enabled + label:hover {\n",
       "  color: var(--xr-font-color0);\n",
       "}\n",
       "\n",
       ".xr-section-summary {\n",
       "  grid-column: 1;\n",
       "  color: var(--xr-font-color2);\n",
       "  font-weight: 500;\n",
       "}\n",
       "\n",
       ".xr-section-summary > span {\n",
       "  display: inline-block;\n",
       "  padding-left: 0.5em;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:disabled + label {\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-section-summary-in + label:before {\n",
       "  display: inline-block;\n",
       "  content: '►';\n",
       "  font-size: 11px;\n",
       "  width: 15px;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:disabled + label:before {\n",
       "  color: var(--xr-disabled-color);\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked + label:before {\n",
       "  content: '▼';\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked + label > span {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-section-summary,\n",
       ".xr-section-inline-details {\n",
       "  padding-top: 4px;\n",
       "  padding-bottom: 4px;\n",
       "}\n",
       "\n",
       ".xr-section-inline-details {\n",
       "  grid-column: 2 / -1;\n",
       "}\n",
       "\n",
       ".xr-section-details {\n",
       "  display: none;\n",
       "  grid-column: 1 / -1;\n",
       "  margin-bottom: 5px;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked ~ .xr-section-details {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-array-wrap {\n",
       "  grid-column: 1 / -1;\n",
       "  display: grid;\n",
       "  grid-template-columns: 20px auto;\n",
       "}\n",
       "\n",
       ".xr-array-wrap > label {\n",
       "  grid-column: 1;\n",
       "  vertical-align: top;\n",
       "}\n",
       "\n",
       ".xr-preview {\n",
       "  color: var(--xr-font-color3);\n",
       "}\n",
       "\n",
       ".xr-array-preview,\n",
       ".xr-array-data {\n",
       "  padding: 0 5px !important;\n",
       "  grid-column: 2;\n",
       "}\n",
       "\n",
       ".xr-array-data,\n",
       ".xr-array-in:checked ~ .xr-array-preview {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-array-in:checked ~ .xr-array-data,\n",
       ".xr-array-preview {\n",
       "  display: inline-block;\n",
       "}\n",
       "\n",
       ".xr-dim-list {\n",
       "  display: inline-block !important;\n",
       "  list-style: none;\n",
       "  padding: 0 !important;\n",
       "  margin: 0;\n",
       "}\n",
       "\n",
       ".xr-dim-list li {\n",
       "  display: inline-block;\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "}\n",
       "\n",
       ".xr-dim-list:before {\n",
       "  content: '(';\n",
       "}\n",
       "\n",
       ".xr-dim-list:after {\n",
       "  content: ')';\n",
       "}\n",
       "\n",
       ".xr-dim-list li:not(:last-child):after {\n",
       "  content: ',';\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".xr-has-index {\n",
       "  font-weight: bold;\n",
       "}\n",
       "\n",
       ".xr-var-list,\n",
       ".xr-var-item {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-var-item > div,\n",
       ".xr-var-item label,\n",
       ".xr-var-item > .xr-var-name span {\n",
       "  background-color: var(--xr-background-color-row-even);\n",
       "  margin-bottom: 0;\n",
       "}\n",
       "\n",
       ".xr-var-item > .xr-var-name:hover span {\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".xr-var-list > li:nth-child(odd) > div,\n",
       ".xr-var-list > li:nth-child(odd) > label,\n",
       ".xr-var-list > li:nth-child(odd) > .xr-var-name span {\n",
       "  background-color: var(--xr-background-color-row-odd);\n",
       "}\n",
       "\n",
       ".xr-var-name {\n",
       "  grid-column: 1;\n",
       "}\n",
       "\n",
       ".xr-var-dims {\n",
       "  grid-column: 2;\n",
       "}\n",
       "\n",
       ".xr-var-dtype {\n",
       "  grid-column: 3;\n",
       "  text-align: right;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-var-preview {\n",
       "  grid-column: 4;\n",
       "}\n",
       "\n",
       ".xr-index-preview {\n",
       "  grid-column: 2 / 5;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-var-name,\n",
       ".xr-var-dims,\n",
       ".xr-var-dtype,\n",
       ".xr-preview,\n",
       ".xr-attrs dt {\n",
       "  white-space: nowrap;\n",
       "  overflow: hidden;\n",
       "  text-overflow: ellipsis;\n",
       "  padding-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-var-name:hover,\n",
       ".xr-var-dims:hover,\n",
       ".xr-var-dtype:hover,\n",
       ".xr-attrs dt:hover {\n",
       "  overflow: visible;\n",
       "  width: auto;\n",
       "  z-index: 1;\n",
       "}\n",
       "\n",
       ".xr-var-attrs,\n",
       ".xr-var-data,\n",
       ".xr-index-data {\n",
       "  display: none;\n",
       "  background-color: var(--xr-background-color) !important;\n",
       "  padding-bottom: 5px !important;\n",
       "}\n",
       "\n",
       ".xr-var-attrs-in:checked ~ .xr-var-attrs,\n",
       ".xr-var-data-in:checked ~ .xr-var-data,\n",
       ".xr-index-data-in:checked ~ .xr-index-data {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       ".xr-var-data > table {\n",
       "  float: right;\n",
       "}\n",
       "\n",
       ".xr-var-name span,\n",
       ".xr-var-data,\n",
       ".xr-index-name div,\n",
       ".xr-index-data,\n",
       ".xr-attrs {\n",
       "  padding-left: 25px !important;\n",
       "}\n",
       "\n",
       ".xr-attrs,\n",
       ".xr-var-attrs,\n",
       ".xr-var-data,\n",
       ".xr-index-data {\n",
       "  grid-column: 1 / -1;\n",
       "}\n",
       "\n",
       "dl.xr-attrs {\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "  display: grid;\n",
       "  grid-template-columns: 125px auto;\n",
       "}\n",
       "\n",
       ".xr-attrs dt,\n",
       ".xr-attrs dd {\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "  float: left;\n",
       "  padding-right: 10px;\n",
       "  width: auto;\n",
       "}\n",
       "\n",
       ".xr-attrs dt {\n",
       "  font-weight: normal;\n",
       "  grid-column: 1;\n",
       "}\n",
       "\n",
       ".xr-attrs dt:hover span {\n",
       "  display: inline-block;\n",
       "  background: var(--xr-background-color);\n",
       "  padding-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-attrs dd {\n",
       "  grid-column: 2;\n",
       "  white-space: pre-wrap;\n",
       "  word-break: break-all;\n",
       "}\n",
       "\n",
       ".xr-icon-database,\n",
       ".xr-icon-file-text2,\n",
       ".xr-no-icon {\n",
       "  display: inline-block;\n",
       "  vertical-align: middle;\n",
       "  width: 1em;\n",
       "  height: 1.5em !important;\n",
       "  stroke-width: 0;\n",
       "  stroke: currentColor;\n",
       "  fill: currentColor;\n",
       "}\n",
       "</style><pre class='xr-text-repr-fallback'>&lt;xarray.Dataset&gt;\n",
       "Dimensions:  (lat: 73, lon: 144, time: 1460)\n",
       "Coordinates:\n",
       "  * lat      (lat) float32 90.0 87.5 85.0 82.5 80.0 ... -82.5 -85.0 -87.5 -90.0\n",
       "  * lon      (lon) float32 0.0 2.5 5.0 7.5 10.0 ... 350.0 352.5 355.0 357.5\n",
       "  * time     (time) datetime64[ns] 2018-01-01 ... 2018-12-31T18:00:00\n",
       "Data variables:\n",
       "    air      (time, lat, lon) float32 ...\n",
       "Attributes:\n",
       "    _NCProperties:                   version=1|netcdflibversion=4.4.1.1|hdf5l...\n",
       "    Conventions:                     COARDS\n",
       "    title:                           4x daily NMC reanalysis (2014)\n",
       "    history:                         created 2017/12 by Hoop (netCDF2.3)\n",
       "    description:                     Data is from NMC initialized reanalysis\\...\n",
       "    platform:                        Model\n",
       "    dataset_title:                   NCEP-NCAR Reanalysis 1\n",
       "    References:                      http://www.psl.noaa.gov/data/gridded/dat...\n",
       "    DODS_EXTRA.Unlimited_Dimension:  time</pre><div class='xr-wrap' style='display:none'><div class='xr-header'><div class='xr-obj-type'>xarray.Dataset</div></div><ul class='xr-sections'><li class='xr-section-item'><input id='section-fecf6a6c-251f-42e2-8e45-fd5030729fb5' class='xr-section-summary-in' type='checkbox' disabled ><label for='section-fecf6a6c-251f-42e2-8e45-fd5030729fb5' class='xr-section-summary'  title='Expand/collapse section'>Dimensions:</label><div class='xr-section-inline-details'><ul class='xr-dim-list'><li><span class='xr-has-index'>lat</span>: 73</li><li><span class='xr-has-index'>lon</span>: 144</li><li><span class='xr-has-index'>time</span>: 1460</li></ul></div><div class='xr-section-details'></div></li><li class='xr-section-item'><input id='section-3b5a97f2-64ee-4330-a459-f5583783610d' class='xr-section-summary-in' type='checkbox'  checked><label for='section-3b5a97f2-64ee-4330-a459-f5583783610d' class='xr-section-summary' >Coordinates: <span>(3)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>lat</span></div><div class='xr-var-dims'>(lat)</div><div class='xr-var-dtype'>float32</div><div class='xr-var-preview xr-preview'>90.0 87.5 85.0 ... -87.5 -90.0</div><input id='attrs-ddff756e-c700-417f-878e-8e8eb37fe73f' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-ddff756e-c700-417f-878e-8e8eb37fe73f' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-e79aadd1-3a09-419c-945a-9dd28ad017c3' class='xr-var-data-in' type='checkbox'><label for='data-e79aadd1-3a09-419c-945a-9dd28ad017c3' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>units :</span></dt><dd>degrees_north</dd><dt><span>actual_range :</span></dt><dd>[ 90. -90.]</dd><dt><span>long_name :</span></dt><dd>Latitude</dd><dt><span>standard_name :</span></dt><dd>latitude</dd><dt><span>axis :</span></dt><dd>Y</dd></dl></div><div class='xr-var-data'><pre>array([ 90. ,  87.5,  85. ,  82.5,  80. ,  77.5,  75. ,  72.5,  70. ,  67.5,\n",
       "        65. ,  62.5,  60. ,  57.5,  55. ,  52.5,  50. ,  47.5,  45. ,  42.5,\n",
       "        40. ,  37.5,  35. ,  32.5,  30. ,  27.5,  25. ,  22.5,  20. ,  17.5,\n",
       "        15. ,  12.5,  10. ,   7.5,   5. ,   2.5,   0. ,  -2.5,  -5. ,  -7.5,\n",
       "       -10. , -12.5, -15. , -17.5, -20. , -22.5, -25. , -27.5, -30. , -32.5,\n",
       "       -35. , -37.5, -40. , -42.5, -45. , -47.5, -50. , -52.5, -55. , -57.5,\n",
       "       -60. , -62.5, -65. , -67.5, -70. , -72.5, -75. , -77.5, -80. , -82.5,\n",
       "       -85. , -87.5, -90. ], dtype=float32)</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>lon</span></div><div class='xr-var-dims'>(lon)</div><div class='xr-var-dtype'>float32</div><div class='xr-var-preview xr-preview'>0.0 2.5 5.0 ... 352.5 355.0 357.5</div><input id='attrs-0e8e7041-52bd-4177-897a-a5bc486e8fd9' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-0e8e7041-52bd-4177-897a-a5bc486e8fd9' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-c9e8614b-2cd2-495b-a58f-146ba10b0ee4' class='xr-var-data-in' type='checkbox'><label for='data-c9e8614b-2cd2-495b-a58f-146ba10b0ee4' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>units :</span></dt><dd>degrees_east</dd><dt><span>long_name :</span></dt><dd>Longitude</dd><dt><span>actual_range :</span></dt><dd>[  0.  357.5]</dd><dt><span>standard_name :</span></dt><dd>longitude</dd><dt><span>axis :</span></dt><dd>X</dd></dl></div><div class='xr-var-data'><pre>array([  0. ,   2.5,   5. ,   7.5,  10. ,  12.5,  15. ,  17.5,  20. ,  22.5,\n",
       "        25. ,  27.5,  30. ,  32.5,  35. ,  37.5,  40. ,  42.5,  45. ,  47.5,\n",
       "        50. ,  52.5,  55. ,  57.5,  60. ,  62.5,  65. ,  67.5,  70. ,  72.5,\n",
       "        75. ,  77.5,  80. ,  82.5,  85. ,  87.5,  90. ,  92.5,  95. ,  97.5,\n",
       "       100. , 102.5, 105. , 107.5, 110. , 112.5, 115. , 117.5, 120. , 122.5,\n",
       "       125. , 127.5, 130. , 132.5, 135. , 137.5, 140. , 142.5, 145. , 147.5,\n",
       "       150. , 152.5, 155. , 157.5, 160. , 162.5, 165. , 167.5, 170. , 172.5,\n",
       "       175. , 177.5, 180. , 182.5, 185. , 187.5, 190. , 192.5, 195. , 197.5,\n",
       "       200. , 202.5, 205. , 207.5, 210. , 212.5, 215. , 217.5, 220. , 222.5,\n",
       "       225. , 227.5, 230. , 232.5, 235. , 237.5, 240. , 242.5, 245. , 247.5,\n",
       "       250. , 252.5, 255. , 257.5, 260. , 262.5, 265. , 267.5, 270. , 272.5,\n",
       "       275. , 277.5, 280. , 282.5, 285. , 287.5, 290. , 292.5, 295. , 297.5,\n",
       "       300. , 302.5, 305. , 307.5, 310. , 312.5, 315. , 317.5, 320. , 322.5,\n",
       "       325. , 327.5, 330. , 332.5, 335. , 337.5, 340. , 342.5, 345. , 347.5,\n",
       "       350. , 352.5, 355. , 357.5], dtype=float32)</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>time</span></div><div class='xr-var-dims'>(time)</div><div class='xr-var-dtype'>datetime64[ns]</div><div class='xr-var-preview xr-preview'>2018-01-01 ... 2018-12-31T18:00:00</div><input id='attrs-45173a57-7b59-45cf-940a-c81c5ef97dc7' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-45173a57-7b59-45cf-940a-c81c5ef97dc7' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-82b7dbd1-679b-44ad-b7ba-81256a64af3b' class='xr-var-data-in' type='checkbox'><label for='data-82b7dbd1-679b-44ad-b7ba-81256a64af3b' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>long_name :</span></dt><dd>Time</dd><dt><span>delta_t :</span></dt><dd>0000-00-00 06:00:00</dd><dt><span>standard_name :</span></dt><dd>time</dd><dt><span>axis :</span></dt><dd>T</dd><dt><span>actual_range :</span></dt><dd>[1910952. 1919706.]</dd><dt><span>_ChunkSizes :</span></dt><dd>512</dd></dl></div><div class='xr-var-data'><pre>array([&#x27;2018-01-01T00:00:00.000000000&#x27;, &#x27;2018-01-01T06:00:00.000000000&#x27;,\n",
       "       &#x27;2018-01-01T12:00:00.000000000&#x27;, ..., &#x27;2018-12-31T06:00:00.000000000&#x27;,\n",
       "       &#x27;2018-12-31T12:00:00.000000000&#x27;, &#x27;2018-12-31T18:00:00.000000000&#x27;],\n",
       "      dtype=&#x27;datetime64[ns]&#x27;)</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-c3284636-d317-4dea-be3c-5f641c20458e' class='xr-section-summary-in' type='checkbox'  checked><label for='section-c3284636-d317-4dea-be3c-5f641c20458e' class='xr-section-summary' >Data variables: <span>(1)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-var-name'><span>air</span></div><div class='xr-var-dims'>(time, lat, lon)</div><div class='xr-var-dtype'>float32</div><div class='xr-var-preview xr-preview'>...</div><input id='attrs-a7d45827-62dd-4952-8ec9-1da759ec070e' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-a7d45827-62dd-4952-8ec9-1da759ec070e' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-404a42a1-92ff-470d-bdfa-7d752b4e4956' class='xr-var-data-in' type='checkbox'><label for='data-404a42a1-92ff-470d-bdfa-7d752b4e4956' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>long_name :</span></dt><dd>4xDaily Air temperature at sigma level 995</dd><dt><span>units :</span></dt><dd>degK</dd><dt><span>precision :</span></dt><dd>2</dd><dt><span>GRIB_id :</span></dt><dd>11</dd><dt><span>GRIB_name :</span></dt><dd>TMP</dd><dt><span>var_desc :</span></dt><dd>Air temperature</dd><dt><span>statistic :</span></dt><dd>Individual Obs</dd><dt><span>parent_stat :</span></dt><dd>Other</dd><dt><span>valid_range :</span></dt><dd>[185.16 331.16]</dd><dt><span>dataset :</span></dt><dd>NCEP Reanalysis</dd><dt><span>actual_range :</span></dt><dd>[189.  323.3]</dd><dt><span>level_desc :</span></dt><dd>0.995 sigma</dd><dt><span>_ChunkSizes :</span></dt><dd>[  1  73 144]</dd></dl></div><div class='xr-var-data'><pre>[15347520 values with dtype=float32]</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-3993e918-bf98-4b42-b6c6-91deed76a419' class='xr-section-summary-in' type='checkbox'  ><label for='section-3993e918-bf98-4b42-b6c6-91deed76a419' class='xr-section-summary' >Indexes: <span>(3)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-index-name'><div>lat</div></div><div class='xr-index-preview'>PandasIndex</div><div></div><input id='index-9c428f95-4684-4348-9e6b-878a17dbcf0d' class='xr-index-data-in' type='checkbox'/><label for='index-9c428f95-4684-4348-9e6b-878a17dbcf0d' title='Show/Hide index repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-index-data'><pre>PandasIndex(Index([ 90.0,  87.5,  85.0,  82.5,  80.0,  77.5,  75.0,  72.5,  70.0,  67.5,\n",
       "        65.0,  62.5,  60.0,  57.5,  55.0,  52.5,  50.0,  47.5,  45.0,  42.5,\n",
       "        40.0,  37.5,  35.0,  32.5,  30.0,  27.5,  25.0,  22.5,  20.0,  17.5,\n",
       "        15.0,  12.5,  10.0,   7.5,   5.0,   2.5,   0.0,  -2.5,  -5.0,  -7.5,\n",
       "       -10.0, -12.5, -15.0, -17.5, -20.0, -22.5, -25.0, -27.5, -30.0, -32.5,\n",
       "       -35.0, -37.5, -40.0, -42.5, -45.0, -47.5, -50.0, -52.5, -55.0, -57.5,\n",
       "       -60.0, -62.5, -65.0, -67.5, -70.0, -72.5, -75.0, -77.5, -80.0, -82.5,\n",
       "       -85.0, -87.5, -90.0],\n",
       "      dtype=&#x27;float32&#x27;, name=&#x27;lat&#x27;))</pre></div></li><li class='xr-var-item'><div class='xr-index-name'><div>lon</div></div><div class='xr-index-preview'>PandasIndex</div><div></div><input id='index-5d412aa3-1dcc-4343-9605-badcc8aed0a8' class='xr-index-data-in' type='checkbox'/><label for='index-5d412aa3-1dcc-4343-9605-badcc8aed0a8' title='Show/Hide index repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-index-data'><pre>PandasIndex(Index([  0.0,   2.5,   5.0,   7.5,  10.0,  12.5,  15.0,  17.5,  20.0,  22.5,\n",
       "       ...\n",
       "       335.0, 337.5, 340.0, 342.5, 345.0, 347.5, 350.0, 352.5, 355.0, 357.5],\n",
       "      dtype=&#x27;float32&#x27;, name=&#x27;lon&#x27;, length=144))</pre></div></li><li class='xr-var-item'><div class='xr-index-name'><div>time</div></div><div class='xr-index-preview'>PandasIndex</div><div></div><input id='index-d1117838-8177-4bff-8fa1-0d6a10aa4476' class='xr-index-data-in' type='checkbox'/><label for='index-d1117838-8177-4bff-8fa1-0d6a10aa4476' title='Show/Hide index repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-index-data'><pre>PandasIndex(DatetimeIndex([&#x27;2018-01-01 00:00:00&#x27;, &#x27;2018-01-01 06:00:00&#x27;,\n",
       "               &#x27;2018-01-01 12:00:00&#x27;, &#x27;2018-01-01 18:00:00&#x27;,\n",
       "               &#x27;2018-01-02 00:00:00&#x27;, &#x27;2018-01-02 06:00:00&#x27;,\n",
       "               &#x27;2018-01-02 12:00:00&#x27;, &#x27;2018-01-02 18:00:00&#x27;,\n",
       "               &#x27;2018-01-03 00:00:00&#x27;, &#x27;2018-01-03 06:00:00&#x27;,\n",
       "               ...\n",
       "               &#x27;2018-12-29 12:00:00&#x27;, &#x27;2018-12-29 18:00:00&#x27;,\n",
       "               &#x27;2018-12-30 00:00:00&#x27;, &#x27;2018-12-30 06:00:00&#x27;,\n",
       "               &#x27;2018-12-30 12:00:00&#x27;, &#x27;2018-12-30 18:00:00&#x27;,\n",
       "               &#x27;2018-12-31 00:00:00&#x27;, &#x27;2018-12-31 06:00:00&#x27;,\n",
       "               &#x27;2018-12-31 12:00:00&#x27;, &#x27;2018-12-31 18:00:00&#x27;],\n",
       "              dtype=&#x27;datetime64[ns]&#x27;, name=&#x27;time&#x27;, length=1460, freq=None))</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-1db2666a-8aca-4e23-9542-9ca944e2fed3' class='xr-section-summary-in' type='checkbox'  checked><label for='section-1db2666a-8aca-4e23-9542-9ca944e2fed3' class='xr-section-summary' >Attributes: <span>(9)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><dl class='xr-attrs'><dt><span>_NCProperties :</span></dt><dd>version=1|netcdflibversion=4.4.1.1|hdf5libversion=1.10.1</dd><dt><span>Conventions :</span></dt><dd>COARDS</dd><dt><span>title :</span></dt><dd>4x daily NMC reanalysis (2014)</dd><dt><span>history :</span></dt><dd>created 2017/12 by Hoop (netCDF2.3)</dd><dt><span>description :</span></dt><dd>Data is from NMC initialized reanalysis\n",
       "(4x/day).  These are the 0.9950 sigma level values.</dd><dt><span>platform :</span></dt><dd>Model</dd><dt><span>dataset_title :</span></dt><dd>NCEP-NCAR Reanalysis 1</dd><dt><span>References :</span></dt><dd>http://www.psl.noaa.gov/data/gridded/data.ncep.reanalysis.html</dd><dt><span>DODS_EXTRA.Unlimited_Dimension :</span></dt><dd>time</dd></dl></div></li></ul></div></div>"
      ],
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:  (lat: 73, lon: 144, time: 1460)\n",
       "Coordinates:\n",
       "  * lat      (lat) float32 90.0 87.5 85.0 82.5 80.0 ... -82.5 -85.0 -87.5 -90.0\n",
       "  * lon      (lon) float32 0.0 2.5 5.0 7.5 10.0 ... 350.0 352.5 355.0 357.5\n",
       "  * time     (time) datetime64[ns] 2018-01-01 ... 2018-12-31T18:00:00\n",
       "Data variables:\n",
       "    air      (time, lat, lon) float32 ...\n",
       "Attributes:\n",
       "    _NCProperties:                   version=1|netcdflibversion=4.4.1.1|hdf5l...\n",
       "    Conventions:                     COARDS\n",
       "    title:                           4x daily NMC reanalysis (2014)\n",
       "    history:                         created 2017/12 by Hoop (netCDF2.3)\n",
       "    description:                     Data is from NMC initialized reanalysis\\...\n",
       "    platform:                        Model\n",
       "    dataset_title:                   NCEP-NCAR Reanalysis 1\n",
       "    References:                      http://www.psl.noaa.gov/data/gridded/dat...\n",
       "    DODS_EXTRA.Unlimited_Dimension:  time"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KeysView(<xarray.Dataset>\n",
       "Dimensions:  (lat: 73, lon: 144, time: 1460)\n",
       "Coordinates:\n",
       "  * lat      (lat) float32 90.0 87.5 85.0 82.5 80.0 ... -82.5 -85.0 -87.5 -90.0\n",
       "  * lon      (lon) float32 0.0 2.5 5.0 7.5 10.0 ... 350.0 352.5 355.0 357.5\n",
       "  * time     (time) datetime64[ns] 2018-01-01 ... 2018-12-31T18:00:00\n",
       "Data variables:\n",
       "    air      (time, lat, lon) float32 ...\n",
       "Attributes:\n",
       "    _NCProperties:                   version=1|netcdflibversion=4.4.1.1|hdf5l...\n",
       "    Conventions:                     COARDS\n",
       "    title:                           4x daily NMC reanalysis (2014)\n",
       "    history:                         created 2017/12 by Hoop (netCDF2.3)\n",
       "    description:                     Data is from NMC initialized reanalysis\\...\n",
       "    platform:                        Model\n",
       "    dataset_title:                   NCEP-NCAR Reanalysis 1\n",
       "    References:                      http://www.psl.noaa.gov/data/gridded/dat...\n",
       "    DODS_EXTRA.Unlimited_Dimension:  time)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataArrays in the Dataset: \n",
      "\t ['air']\n"
     ]
    }
   ],
   "source": [
    "print(f\"DataArrays in the Dataset: \\n\\t {list(ds.keys())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variables in the Dataset: \n",
      "\t ['lat', 'lon', 'time', 'air']\n"
     ]
    }
   ],
   "source": [
    "print(f\"Variables in the Dataset: \\n\\t {list(ds.variables.keys())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions in the Dataset: \n",
      "\t ['lat', 'lon', 'time']\n"
     ]
    }
   ],
   "source": [
    "print(f\"Dimensions in the Dataset: \\n\\t {list(ds.dims.keys())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coordinates in the Dataset: \n",
      "\t ['lat', 'lon', 'time']\n"
     ]
    }
   ],
   "source": [
    "print(f\"Coordinates in the Dataset: \\n\\t {list(ds.coords.keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the global attributes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dts_attribute = ds.attrs\n",
    "dts_attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dts_attribute['description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dts_attribute['References']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='blue'>Work With the NetCDF Data Structure </font>\n",
    "\n",
    "- An Xarray contains metadata making it self-describing. \n",
    "- There are three dimensions to consider when working with this data which represent the `x`, `y` and `z` dimensions of the data:  \n",
    "     - latitude/longitude/time.\n",
    "- This particular dataset contains global time series of surface air temperatures for 2018."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Get the Air Temperature dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "air_temp2D = ds.air\n",
    "air_temp2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Get latitude/longitude information**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Latitude values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "air_temp2D['lat'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "air_temp2D['lat'].attrs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Minimum/Maximum latidtude and longitude:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Min/Max latitudes: \\n\\t {air_temp2D['lat'].values.min()} {air_temp2D['lat'].values.max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Min/Max longitudes: \\n\\t {air_temp2D['lon'].values.min()} {air_temp2D['lon'].values.max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Get the time information**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "air_temp2D[\"time\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Earliest date: {air_temp2D['time'].values.min()}\")\n",
    "print(f\"Latest   date: {air_temp2D['time'].values.max()}\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(air_temp2D[\"time\"].values))\n",
    "print(air_temp2D[\"time\"].values.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Self describing dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = air_temp2D.attrs\n",
    "metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metadata['units'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Slicing the data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select a single `x`, `y` combination from the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = 50\n",
    "longitude = air_temp2D[\"lon\"].values[key]\n",
    "latitude = air_temp2D[\"lat\"].values[key]\n",
    "\n",
    "print(f\"Longitude = {longitude} \\n Latitude = {latitude}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the selected location on a map:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12, 9))\n",
    "map_projection = ccrs.PlateCarree()\n",
    "data_transform = ccrs.PlateCarree()\n",
    "\n",
    "ax = plt.axes(projection=map_projection)\n",
    "ax.stock_img()\n",
    "\n",
    "# Plot the selected location \n",
    "plt.plot([longitude], [latitude], 'r*', \n",
    "        transform=data_transform,\n",
    "        color=\"purple\", \n",
    "         markersize=10)\n",
    "\n",
    "ax.set(title=f\"Location of the {latitude} Lat and {longitude} Lon Being Used to Slice Your netcdf Climate Data File\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the time series data at the selected location:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_point = air_temp2D.sel(lat=latitude, lon=longitude)\n",
    "one_point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- When you slice the data by a single point, the output data only has a single array of values. \n",
    "- The values represent air temperature (in K) over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_point.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can get the first few values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_point.values[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Time series plot at a single location**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_point.plot.line();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can make the plot a bit prettier by using Matplotlib plot parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(12, 6))\n",
    "one_point.plot.line(ax=ax, marker=\"o\", color=\"grey\",\n",
    "                    markerfacecolor=\"purple\",\n",
    "                    markeredgecolor=\"purple\");\n",
    "ax.set(title=\"Time Series For a Single Lat/Lon Location\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='blue'> Slice the Data By Time and Location</font>\n",
    "- We want to slice the data at a selected lat/lon location and for the months of April to June."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beg_date = \"2018-04-01\"\n",
    "end_date = \"2018-06-30\"\n",
    "temp_apr_jun = air_temp2D.sel(time=slice(beg_date, end_date),\n",
    "                              lat=latitude, lon=longitude)\n",
    "temp_apr_jun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(temp_apr_jun.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can plot the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(12, 6))\n",
    "temp_apr_jun.plot.line(ax=ax, marker=\"o\", color=\"grey\",\n",
    "                       markerfacecolor=\"purple\",\n",
    "                       markeredgecolor=\"purple\")\n",
    "ax.set(title=\"April-June Time Series of Temperature Data For A Single Location\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='blue'> Time series at specific latitudes and along a longitude line</font>\n",
    "\n",
    "- We can use line plots to check the variation of air temperature at three different latitudes along a longitude line:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(12, 6))\n",
    "air_temp2D.isel(lon=10, lat=[19, 21, 22]).plot.line(x=\"time\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='blue'> Slice The Data Across a Spatial Extent For A Specific Time Period</font>\n",
    "\n",
    "- We use `.sel()` combined with `slice()` to subset the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beg_date = \"2018-04-01\"\n",
    "end_date = \"2018-04-01\"\n",
    "one_day_data = air_temp2D.sel(time=slice(beg_date, end_date))\n",
    "one_day_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_day_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we call `.plot()` on the data, the default plot is a histogram representing the range of raster pixel values in your data for all time periods (3 months in this case)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_day_data.plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='blue'>Spatial Plots</font>\n",
    "- If you want to plot the data spatially as a raster, you can use `.plot()` but specify the lon and lat values as the x and y dimensions to plot. \n",
    "- You can add the following parameters to your .plot() call to make sure each time step in your data plots spatially:\n",
    "    - `col_wrap=`: adjust how how many columns the each subplot is spread across \n",
    "    - `col=`: what dimension is being plotted in each subplot.\n",
    "\n",
    "Here, we want a single raster for each time record in the data so you specify `col='time'`. `col_wrap=2` forces the plots to be on two columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot at a specific date:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_time = one_day_data.time.values[-1]\n",
    "one_day_data.sel(time=last_time).plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot for all the dates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_day_data.plot(x=\"lon\", y=\"lat\", col=\"time\", col_wrap=2)\n",
    "plt.suptitle(\"One day Air Temp\", y = 1.05);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Use the Cartopy map projection:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_projection = ccrs.PlateCarree()\n",
    "data_transform = ccrs.PlateCarree()\n",
    "\n",
    "aspect = one_day_data.shape[2] / one_day_data.shape[1]\n",
    "\n",
    "p = one_day_data.plot(transform=data_transform,  # the data's projection\n",
    "                      col='time', col_wrap=2,\n",
    "                      aspect=aspect,\n",
    "                      figsize=(10, 10),\n",
    "                      subplot_kws={'projection': map_projection})  # the plot's projection\n",
    "\n",
    "for ax in p.axes.flat:\n",
    "    ax.coastlines()\n",
    "    #ax.set_extent(extent)\n",
    "\n",
    "plt.suptitle(\"One day Air Temp\", y = 1.0);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use Cartopy only to do the countour plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = [15, 12]\n",
    "fig = plt.figure(tight_layout=False)\n",
    "nrows, ncols = 2, 2\n",
    "for i in range(4):\n",
    "    ax = fig.add_subplot(nrows, ncols, i+1, projection=map_projection)\n",
    "    one_day_data[i].plot()\n",
    "    ax.coastlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cartopy.util\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = [15, 12]\n",
    "fig = plt.figure(tight_layout=False)\n",
    "nrows, ncols = 2, 2\n",
    "#fig, axes = plt.subplots(nrows=nrows, ncols=ncols)\n",
    "#ax = axes.ravel()\n",
    "\n",
    "for i in range(4):\n",
    "    ax = fig.add_subplot(nrows, ncols, i+1, projection=map_projection)\n",
    "    data = one_day_data[i].values\n",
    "    lats = one_day_data[i]['lat'].values\n",
    "    lons = one_day_data[i]['lon'].values\n",
    "\n",
    "    data, lons = cartopy.util.add_cyclic_point(data, coord=lons)\n",
    "    cp = plt.contourf(lons, lats, data, 60,\n",
    "                      cmap='jet', transform=ccrs.PlateCarree())\n",
    "    ax.coastlines()\n",
    "    title = f'Time = {str(one_day_data[i].time.values)[0:19]}'\n",
    "    ax.set_title(title)\n",
    "\n",
    "# add a subplot for vertical colorbar\n",
    "bottom, top = 0.1, 0.9\n",
    "left, right = 0.1, 0.8\n",
    "fig.subplots_adjust(top=top, bottom=bottom, \n",
    "                    left=left, right=right, hspace=0.15, wspace=0.25)\n",
    "cbar_ax = fig.add_axes([0.85, bottom, 0.05, top-bottom])\n",
    "fig.colorbar(cp, cax=cbar_ax);  # plot colorbar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='blue'> Perform Correlation Analysis</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Group the dataset by month:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grp_air_temp  = air_temp2D.groupby('time.month')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grp_air_temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the monthly climatologies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "air_temp_clim = grp_air_temp.mean(dim='time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "air_temp_clim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the anomaly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "air_temp_anom = grp_air_temp - air_temp_clim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "air_temp_anom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the anomaly for the first time record:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "air_temp_anom[0].plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot anomaly time series at a specific location:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "air_temp_ref = air_temp_anom.sel(lon=200, lat=0, method='nearest')\n",
    "air_temp_ref.plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def covariance(x, y, dims=None):\n",
    "    return xr.dot(x - x.mean(dims), y - y.mean(dims), dims=dims) / x.count(dims)\n",
    "\n",
    "def corrrelation(x, y, dims=None):\n",
    "    return covariance(x, y, dims) / (x.std(dims) * y.std(dims))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "air_temp_cor = corrrelation(air_temp_anom, air_temp_ref, dims='time')\n",
    "pc = air_temp_cor.plot()\n",
    "pc.axes.set_title('Correlation btw. global airTemp Anomaly and airTemp Anomaly at one point');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determine the time series spatial means:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "air_temp_anom_avg = air_temp_anom.mean(dim=['lat', 'lon'])\n",
    "air_temp_anom_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "air_temp_anom_avg.plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpolation using datetime strings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inter_data = air_temp2D.interp(time=[\"2018-03-15\", \"2018-03-16\"])\n",
    "inter_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inter_data.plot(x=\"lon\", y=\"lat\", col=\"time\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='blue'>Manipulating 3D Field </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Access the file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_3D=\"https://psl.noaa.gov/thredds/dodsC/Datasets/ncep.reanalysis.dailyavgs/pressure/air.2020.nc\"\n",
    "xds = xr.open_dataset(url_3D)\n",
    "xds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List all the dimension values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xds.level.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xds.lon.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xds.lat.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the 3D temperature:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "air_temp3D = xds.air"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time series plots at `600 mb`, `25.0` degree longitude and at three latitudes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "air_temp3D.sel(level=600., lon=25.0).isel(lat=[19, 21, 22]).plot.line(x=\"time\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What happens if I what to do the same plot at longitude `24.5`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "air_temp3D.sel(level=600., lon=24.5).isel(lat=[19, 21, 22]).plot.line(x=\"time\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to perform an interpolation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "air_temp3D.sel(level=600.).isel(lat=[19, 21, 22]).interp(lon=24.5).plot.line(x=\"time\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "air_temp3D.sel(level=600.).interp(lon=24.5, lat=21.0).plot.line(x=\"time\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get monthly means:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_air_temp3D = air_temp3D.groupby('time.month').mean(dim='time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_air_temp3D.sel(level='1000.0').plot(x=\"lon\", y=\"lat\",\n",
    "                                           col=\"month\",\n",
    "                                           col_wrap=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Annual Mean: Contour plot at each vertical level:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "air_temp3D.mean(dim='time').plot(x=\"lon\", y=\"lat\",\n",
    "                                           col=\"level\",\n",
    "                                           col_wrap=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform the Zonal Mean Height plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(15, 12))\n",
    "air_temp3D.mean(dim='time').mean(dim='lon').plot(ax=ax, \n",
    "                                                 x='lat', \n",
    "                                                 y='level')\n",
    "ax.set_xlabel('Latitude')\n",
    "ax.set_ylabel('Vertical Level')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='green'> Exercise</font>\n",
    "\n",
    "Modify the code shown in:\n",
    "\n",
    "[https://www.nccs.nasa.gov/nccs-users/instructional/adapt-instructional/python/xarray-generating-climatology-dataset-using-CMIP6](https://www.nccs.nasa.gov/nccs-users/instructional/adapt-instructional/python/xarray-generating-climatology-dataset-using-CMIP6)\n",
    "\n",
    "to reproduce the plot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "<p>\n",
    "\n",
    "<details><summary><b><font color='green'>Click here to access the solution</font></b></summary>\n",
    "<p>\n",
    "\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "URL ='https://esgf.nccs.nasa.gov/thredds/dodsC/CMIP6.CMIP.NASA-GISS.GISS-E2-1-G.historical.r1i1p1f1.Amon.tas.gn.tas.20180827.aggregation.1'\n",
    "nc = xr.open_dataset(URL, engine='netcdf4')\n",
    "\n",
    "# do the average of the each month over 164 years\n",
    "da = nc['tas']\n",
    "slice_da = da.sel(lat=slice(18.92, np.max(da.lat.values)),\n",
    "                  lon=slice(188.30, np.max(da.lon.values)))\n",
    "\n",
    "monthly_data = slice_da.groupby('time.month').mean('time')\n",
    "monthly_data.plot(x=\"lon\",\n",
    "                y=\"lat\",\n",
    "                col=\"month\",\n",
    "                col_wrap=3,\n",
    "                cmap='jet')\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "</p>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='red'>Application: Subsetting a Dataset and Writing in File</font>\n",
    "\n",
    "- We read a multi-year GEOS-5 dataset that contains 16 fields (`u`, `v`, `epv`, `delp`, `t`, etc.)\n",
    "- We select the variable `t` (3D air temperature) with a latitude from 80N to 82N, a longitude from 72W to 70W, and a time from February 1, 2024 to March 5, 2024.\n",
    "- We perform analyses.\n",
    "- We write out the slice in a netCDF file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geos5_url ='https://opendap.nccs.nasa.gov/dods/GEOS-5/fp/0.25_deg/assim/tavg3_3d_asm_Nv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geos5_xrs = xr.open_dataset(geos5_url, engine='netcdf4')\n",
    "geos5_xrs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What is the Dataset size?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geos5_xrs.sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_records = dict(geos5_xrs.sizes)['time']\n",
    "num_records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_size(geos5_xrs.nbytes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What is the time range?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Starting Time: \\n\\t {geos5_xrs.time.values[0]}\")\n",
    "print(f\"Ending Time:   \\n\\t {geos5_xrs.time.values[-1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What is the time resolution?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Time resolution: {geos5_xrs.time.attrs['resolution']} day\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Take a slice of the air temperature field:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beg_date = \"2024-02-01T01:30:00\"\n",
    "end_date = \"2024-03-05T22:30:00\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_ds = geos5_xrs.t.sel(lat=slice(80, 82), \n",
    "                       lon=slice(-72,-70), \n",
    "                       time=slice(beg_date, end_date))\n",
    "t_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot the time series of mean surface temperature:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(12, 6))\n",
    "t_ds.sel(lev=72).mean(dim=[\"lat\", 'lon']).plot.line(ax=ax, marker=\"o\", color=\"grey\",\n",
    "                       markerfacecolor=\"purple\",\n",
    "                       markeredgecolor=\"purple\", label=\"Local Domain\")\n",
    "geos5_xrs.t.sel(lev=72,\n",
    "                time=slice(beg_date, \n",
    "                           end_date)).mean(dim=[\"lat\", 'lon']).plot.line(color=\"green\", label=\"Entire Domain\")\n",
    "\n",
    "plt.legend(ncol=2);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot the time average surface temperature:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_ds.sel(lev=72).mean(dim=\"time\").plot(x=\"lon\", y=\"lat\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Control the axes direction:\n",
    "- The keyword arguments `xincrease` and `yincrease` let you control the axes direction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(12, 6))\n",
    "t_ds.sel(lev=72).mean(dim=[\"lat\", 'lon']).plot.line(ax=ax, \n",
    "                                                    xincrease=False, \n",
    "                                                    yincrease=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Contour Plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_ds.sel(lev=72).mean(dim=\"time\").plot.contour(x=\"lon\", y=\"lat\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_ds.sel(lev=72).mean(dim=\"time\").plot.contourf(x=\"lon\", y=\"lat\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We can combine two plots into subplots:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 6), ncols=2)\n",
    "t_ds.sel(lev=72).mean(dim=[\"lat\", 'lon']).plot.line(ax=ax[0], \n",
    "                                                    marker=\"o\", \n",
    "                                                    color=\"grey\",\n",
    "                                                    markerfacecolor=\"purple\",\n",
    "                                                    markeredgecolor=\"purple\");\n",
    "\n",
    "t_ds.sel(lev=72).mean(dim=\"time\").plot.contourf(x=\"lon\", y=\"lat\", ax=ax[1]);\n",
    "#t_ds.sel(lev=72).mean(dim=\"time\").plot(x=\"lon\", y=\"lat\", ax=ax[1])\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We can save the slice in a netCDF file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#t_ds.to_netcdf(\"air_temperature_subset.nc\", engine='netcdf4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"red\">Using Dask to read data by chunks</font>\n",
    "\n",
    "- The above dataset is very large (over 48 TB).\n",
    "- The dataset cannot fit into memory but Dask was able to read the entire dataset (as needed) and perform analysis.\n",
    "- Xarray integrates with Dask to support parallel computations and streaming computation on datasets that don’t fit into memory.\n",
    "  - Dask divides arrays into many small pieces, called chunks, each of which is presumed to be small enough to fit into memory.\n",
    "  - We can supply a `chunks` arugment to `open_dataset()` or using the `open_mfdataset()` (when we deal with multiple files) function.\n",
    "  - `chunks` is a dictionary setting the chunk size of each dimension in the dataset.\n",
    "  - The read in data will at the end be Dask arrays. Lazy computations with `compute()` will ne needed to perform analyses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"blue\">How to select the chunk size for a large dataset?</font>\n",
    "\n",
    "#### General principles: \n",
    "\n",
    "- Too small chunk: huge overheads.\n",
    "- Poorly aligned with data: inefficient reading.\n",
    "- Recommended to have a chuck size of at least 100 Mb.\n",
    "- Choose a chunk size that is large in order to reduce the number of chunks that Dask has to think about (which affects overhead) but also small enough so that many of them can fit in memory at once. **Dask will often have as many chunks in memory as twice the number of active threads**.\n",
    "- __Upper bound__: Avoid too large task graphs. More than 10,000 or 100,000 chunks may start to perform poorly.\n",
    "- __Lower bound__: To get the advantage of parallelization, you need the number of chunks to at least equal the number of worker cores available (or better, the number of worker cores times 2). Otherwise, some workers will stay idle.\n",
    "\n",
    "To follow the above principles, we want to choose the chunk size that can fit into memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#chunks={'time': 1, 'lev': -1, 'lat': -1, 'lon': -1}\n",
    "chunks={'time': 10, \"lev\": 1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example `lev`, `lat` and `lon` do not appear in the `chunks` dict, so only one chunk will be used along those dimensions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geos5_xrs_chk = xr.open_dataset(geos5_url, \n",
    "                                engine='netcdf4',\n",
    "                                chunks=chunks)\n",
    "geos5_xrs_chk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geos5_xrs_chk.sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_size(geos5_xrs_chk.nbytes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_ds_chk = geos5_xrs_chk.t.sel(lat=slice(80, 82), \n",
    "                       lon=slice(-72,-70), \n",
    "                       time=slice(beg_date, end_date))\n",
    "t_ds_chk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_ds_chk.sel(lev=72).mean(dim=\"time\").compute().plot(x=\"lon\", y=\"lat\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_ds_chk.sel(lev=72).mean(dim=\"time\").plot.contourf(x=\"lon\", y=\"lat\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(12, 6))\n",
    "t_ds_chk.sel(lev=72).mean(dim=[\"lat\", 'lon']).compute().plot.line(ax=ax, marker=\"o\", color=\"grey\",\n",
    "                       markerfacecolor=\"purple\",\n",
    "                       markeredgecolor=\"purple\", label=\"Local Domain\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='red'>Reading Multiple netCDF Files</font>\n",
    "\n",
    "- The function `open_mfdataset()` opens multiple files as a single dataset.\n",
    "- Requires `Dask` to be installed.\n",
    "- The attributes from the first dataset file are used for the combined dataset.\n",
    "- If you pass the argument `parallel=True`, all the files will be simultaneously opened in parallel using Dask delayed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">[!WARNING]\n",
    "> `open_mfdataset()` called without chunks argument will return dask arrays with chunk sizes equal to the individual files. Re-chunking the dataset after creation with ds.chunk() will lead to an ineffective use of memory and is not recommended."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading Multiple NCEP Reanalysis Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://psl.noaa.gov/thredds/dodsC/Datasets/ncep.reanalysis/surface'\n",
    "byear = 2017\n",
    "eyear = 2019\n",
    "list_files = ['{0}/air.sig995.{1:04d}.nc'.format(url, years) \n",
    "              for years in range(byear,eyear,1)]\n",
    "list_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.open_mfdataset(list_files)\n",
    "print(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dst_airT = ds.air\n",
    "dst_airT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dst_airT.data.visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Select data for a given time range:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "air_temp2017 = dst_airT.sel(time=slice(\"2017-01-01\", \"2017-12-31\"))\n",
    "air_temp2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "air_temp2017.data.visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compute the daily means:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_dst = dst_airT.resample(time='1D').mean()\n",
    "daily_dst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time series plot at Greenbelt, MD location:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat_ref =  39.00\n",
    "lon_ref = -76.88\n",
    "daily_dst_ref = daily_dst.sel(lon=lon_ref, lat=lat_ref, method='nearest')\n",
    "daily_dst_ref.to_pandas().T.plot()\n",
    "units = dst_airT.attrs['units']\n",
    "plt.ylabel(f\"Air Temperature ({units})\")\n",
    "plt.title('Time series plot for Greenbelt');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compute the monthly means:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_dst = dst_airT.resample(time='1M').mean()\n",
    "monthly_dst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_dst.data.visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compute the annual means:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yearly_dst = dst_airT.resample(time='1A').mean()\n",
    "yearly_dst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yearly_dst.plot(x=\"lon\", y=\"lat\",\n",
    "                col=\"time\", col_wrap=2)\n",
    "plt.suptitle(\"Yearly Means\", y = 1.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compute seasonal values:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For seasons `JFM`, `AMJ`, `JAS` and `OND`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "JFM_dst = dst_airT.resample(time='QS-JAN').mean()\n",
    "JFM_dst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "JFM_dst.plot(x=\"lon\", y=\"lat\", col=\"time\", col_wrap=3)\n",
    "plt.suptitle(\"Seasonal Means (JFM, AMJ, JAS, OND)\", y = 1.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For seasons `DJF`, `MAM`, `JJA` and `SON`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DJF_dst = dst_airT.resample(time='QS-DEC').mean()\n",
    "DJF_dst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or you can use the following for the seasons `DJF`, `MAM`, `JJA`, `SON`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DJF_dst2 = dst_airT.groupby('time.season').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DJF_dst.plot(x=\"lon\", y=\"lat\", col=\"time\", col_wrap=3)\n",
    "plt.suptitle(\"Seasonal Means (DJF, MAM, JJA, SON)\", y = 1.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"purple\">Accessing HDF5 Files (INCOMPLETE)</font>\n",
    "\n",
    "- Reading HDF5 files in xarray requires the `h5netcdf` engine, which can be installed with `conda install h5netcdf`.\n",
    "- Xarray cannot interrogate an HDF5 file to determine which groups are available.\n",
    "- If you have multiple or highly nested groups, a particular group of an HDF5 file can be specified using the group argument."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open the hdf5-file using netCDF4 in diskless non-persistence mode:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import netCDF4 as nc4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('sample_hdf5.h5', <http.client.HTTPMessage at 0x142bff0d0>)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import urllib.request\n",
    "url = \"https://raw.githubusercontent.com/astg606/py_materials/master/xarray/sample_hdf5.h5\"\n",
    "hdf5_fname = \"sample_hdf5.h5\"\n",
    "urllib.request.urlretrieve(url, hdf5_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncf = nc4.Dataset(hdf5_fname, diskless=True, persist=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can inspect the file contents including `groups`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'2D_Data': <class 'netCDF4._netCDF4.Group'>\n",
      "group /2D_Data:\n",
      "    Description: Group for 2D variables\n",
      "    Sub groups: Land and Sea\n",
      "    dimensions(sizes): \n",
      "    variables(dimensions): \n",
      "    groups: 2D_Land, 2D_Sea, '3D_Data': <class 'netCDF4._netCDF4.Group'>\n",
      "group /3D_Data:\n",
      "    Description: Group for 2D variables\n",
      "    dimensions(sizes): phony_dim_3(5), phony_dim_4(20), phony_dim_5(46), phony_dim_6(90)\n",
      "    variables(dimensions): float64 temp(phony_dim_3, phony_dim_4, phony_dim_5, phony_dim_6)\n",
      "    groups: }\n"
     ]
    }
   ],
   "source": [
    "print(ncf.groups)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can make use of `xarray.backends.NetCDF4DataStore` to open the wanted hdf5-groups (Xarray can only get hold of one hdf5-group at a time):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdf5_group_name = '3D_Data'\n",
    "nch = ncf.groups.get(hdf5_group_name)\n",
    "xds = xr.open_dataset(xr.backends.NetCDF4DataStore(nch))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This will give you a dataset `xds` with all attributes and variables (datasets) of the group hdf5-name. \n",
    "- Note that you will not get access to sub-groups. \n",
    "- You would need to claim subgroups by the same mechanism. \n",
    "- If you want to apply Dask, you would need to add the keyword chunking with wanted values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = xds.temp\n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp.isel(phony_dim_3=1, phony_dim_4=2).plot(x=\"phony_dim_6\", \n",
    "                                             y=\"phony_dim_5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decoding data\n",
    "\n",
    "- There is no (real) automatism for decoding data like this could be done for NetCDF files. \n",
    "- If you have a integer compressed 2d variable (dataset) `var` with some attributes `gain` and `offset` you can add the NetCDF specific attributes `scale_factor` and `add_offset` to the variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_name = ''\n",
    "var = xds[var_name]\n",
    "var.attrs['scale_factor'] = var.attrs.get('gain')\n",
    "var.attrs['add_offset'] = var.attrs.get('offset')\n",
    "ds = xarray.decode_cf(xds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will decode your variable using netcdf mechanisms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- You could try to give the extracted dimension useful names (you will get something like phony_dim_0, phony_dim_1, ..., phony_dim_N) and assign new (as in example) or existing variables/coordinates to those dimensions to gain as much of the xarray machinery:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var = xds[var_name]\n",
    "var.attrs['scale_factor'] = var.attrs.get('gain')\n",
    "var.attrs['add_offset'] = var.attrs.get('offset')\n",
    "dims = var.dims\n",
    "xds[var_name] = var.rename({dims[0]: 'x', dims[1]: 'y'})\n",
    "xds = xds.assign({'x': (['x'], xvals, xattrs)})\n",
    "xds = xds.assign({'y': (['y'], yvals, yattrs)})\n",
    "ds = xarray.decode_cf(xds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
